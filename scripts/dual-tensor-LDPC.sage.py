

# This file was *autogenerated* from the file ./dual-tensor-LDPC.sage
from sage.all_cmdline import *   # import sage library

_sage_const_2 = Integer(2); _sage_const_0 = Integer(0); _sage_const_1 = Integer(1); _sage_const_200 = Integer(200); _sage_const_100 = Integer(100); _sage_const_3 = Integer(3); _sage_const_4 = Integer(4); _sage_const_5 = Integer(5); _sage_const_20 = Integer(20); _sage_const_15 = Integer(15)
import sage.coding.linear_code as lnc
import numpy as np
from copy import deepcopy
from matplotlib import pyplot as plt
import datetime
import pickle as pkl
class DualTensorCode(lnc.LinearCode):


    def __init__(self, codeA, codeB):
        self.codeA, self.codeB = codeA, codeB
        gen = lnc.LinearCode(codeA.dual_code().product_code(                codeB.dual_code())).dual_code().generator_matrix()
        super().__init__(gen)

    def reshape_to_matrix(self, element):
        return element.numpy().reshape((self.codeA.length( ), self.codeB.length( )))
    def random_test_case(self):
        return self.reshape_to_matrix(self.random_element())    
    def codes(self):
        return [ self.codeA, self.codeB ] 

    def decompose(self, element):
        decoders = [ codes.decoders.LinearCodeNearestNeighborDecoder(C) for C in self.codes() ] 
        codeword = self.reshape_to_matrix(element)
        parts = [ [], [] ]
        for i, decoder in enumerate(decoders):
            for raw in codeword:
                parts[i].append(decoder.decode_to_code(                        vector( GF(_sage_const_2 ), raw.tolist() )))
            codeword = codeword.transpose()
        return parts

    def count_support(self, element):
        def nonzeor(v):
            for u in v:
                if u != _sage_const_0 :
                    return _sage_const_1 
            return _sage_const_0 
        parts = self.decompose(element)
        return [sum(map(nonzeor, part)) for part in parts]



def sample_light_codewords(code, T, _filter):
    while T > _sage_const_0 : 
        codeword = code.random_element()
        print(codeword.hamming_weight())
        lifes = _sage_const_200 
        while (codeword.hamming_weight() > _filter):
       #     print(codeword.hamming_weight())
            codeword = code.random_element()
            lifes -= _sage_const_1 
            if lifes <= _sage_const_0 :
                yield False, False
        yield True, codeword
        T -= _sage_const_1 

def w_robust_check(code):
    print(code.length())
    T, X, Y = _sage_const_100 , [], []
    for flag, codeword in sample_light_codewords(code,T,code.length()**(_sage_const_3 /_sage_const_4 )):
        if not flag:
            return False 
        Y.append(sum(code.count_support(codeword)))
        X.append(codeword.hamming_weight())
    plt.scatter(X,Y, c="black", s=_sage_const_5 )
    plt.savefig(f"./svg/exp-{code.length()}-{code.dimension()}-{datetime.datetime.now()}.svg")
    pkl.dump(code, open(f"./pkl/exp-{code.length()}-{code.dimension()}-{datetime.datetime.now()}.pkl", "bw"))
    #weight = np.sum(codeword)
    return True    
def test_Dual_Tensor_basics():
    flag = False
    while not flag:
        C = codes.random_linear_code(GF(_sage_const_2 ), _sage_const_20 , _sage_const_15 ) 
        G = DualTensorCode(C,C)    
        flag = w_robust_check(G)

test_Dual_Tensor_basics()




