We are going to introduce the polynomial code in an opposite order as in the usual literature. Instead of starting by presenting polynomials and the code itself we will begin by defining an abstract decoder, and define the code to be all the strings on which the decoder is apathetic. Consider the alphabet $\Sigma$, and let $D$ be a decoder such that on every $d+1$ coordinate $x_1,x_2, .. x_{d+1}$ and candidate for a code word $c$, read $c_1, c_2 .. c_{d}$ and returns a charter in $\Sigma$. We will think of $D$ as tester also. On given candidate $c \in \Sigma^{n}$, $D$ accept if for any $x_1,x_2.. x_{d+1}$ it holds that $C_{d+1} = D\left(c; x_1, x_2 .. x_{d+1} \right)$. We will associciate a single check with spesific $d+1$ coordinates.   

The setting avbove is kind general, and we will need to rquire form the code more to be a locally testable. Let us define the following property which could be thought as induction for cheks degenration:

\begin{definition}
  We will say that code $C$ has the \textit{degeneration} property if for any chack $h$ there is a set of checks $H\left( h \right)$ such that: 
  \begin{enumerate}
    \item if $H$ satisfied then also $h$ satisifed. 
    \item it easy to chack $H$.  
  \end{enumerate} 
\end{definition}

Denote by $V(x)$ the vandermode matrix defined by $x$ namely $V(x)_{ij} = x_{i}^{j}$. and by $w$ the $d$ root of $1$. Now $\sum_{t}{ V\left( x +  w^{t}y \right)  } = t \cdot \left(V(x) + V(y) \right)$.   


\begin{claim}The code defined by all the strings on which $D$ accept with probability $1$, when the randomness is over the sampled coordinates $x_{1}, x_{2} .. x_{d+1}$ is a locally testable code. In particular, if the $c$ is in the code, then a random check successes with probability $1$ and for every $c$ that is $\varepsilon$-far from the code the probability to, accept  is at most $ { d \choose 2 } |\Sigma| \varepsilon $.  
\end{claim}

\begin{proof}
  Notice that by definition if the tester accept with probability $1$ then $c \in C$. Suppose that $c$ pass the test with probability at least $1 - \varepsilon$. First, let us define the codeword $l$ such that $ l_{y} = Majoritiy_{x_1 .. x_{d}}D\left(c, x_{1}.. x_{d},y\right)$.

  \begin{claim} 
    The distance between $l$ and $c$ is at most $ 1- \left( 1 - \frac{1}{\Sigma} \right)^{-1}\varepsilon$.  
  \end{claim}
  \begin{proof} 
    Denote by $\alpha$ the probability that for given $y$, $D$ accept on more then $\frac{1}{|\Sigma|}$ fraction to choose $x_{1},x_{2}..x_{d}$. 
    Then we have that:  
    
    \begin{equation*}
      \begin{split}
        1 - \varepsilon  & \le \prbm{ D\left( x_1 .. x_{d+1} \right) }{x_1 .. x_{d+1}}  \\
        & = \prbcprb{  D\left( x_1 .. x_{d+1} \right)}{ x_1 .. x_{d+1}  }{ x_{d+1} \in A } + \\
        & \ \ \ \ \ \ \prbcprb{ D\left( x_1 .. x_{d+1} \right)}{ x_1 .. x_{d+1}   }{ x_{d+1} \notin A } \\
        & \le 1 \cdot \alpha +  \frac{1}{|\Sigma|}  \left( 1 - \alpha \right) = \left( 1 - \frac{1}{|\Sigma|} \right) \alpha  + \frac{1}{|\Sigma|} \\
       & \Rightarrow \alpha \ge  1- \left( 1 - \frac{1}{\Sigma} \right)^{-1}\varepsilon
      \end{split}
    \end{equation*}
  \end{proof} 

  So we showed that $l$ and $c$ are close. It's left to show that $l$ is a code word, namely that any check by $D$ pass. Fix a check, which equivalence as fix $d+1$ coordinates $x_{1} .. x_{d+1}$. Now notice that by the degenration property if there exists $y$ such that for every $i \in [d+1]$ $D\left(l; y_{1} .. y_{d}, x_{i} \right) = l_{x_{i}}$ than it follows that also $D\left(l; x_{1} .. x_{d+1} \right)$ pass.  
  \begin{equation*}
    \begin{split}
      \left\{ D(G(c) ; x ) \right\} \subset \bigcap_{ x_{i} } \left\{ D\left( x_{i} ; y_{1} .. y_{d} \right)  \right\} 
    \end{split}
  \end{equation*}
\end{proof}


