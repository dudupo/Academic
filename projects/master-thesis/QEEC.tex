\chapter{Quantum Error Correction Codes.}
\section{Introduction.}
It's wide believed that quantum machines have a significant advantage over the classical in range of computational tasks\cite{grover1996fast}, \cite{ahuja1999quantum}. Simple algorithms, which could be interpreted as the quantum version of scanning all the options cut the running time by square root of the classical magnitude. 

Nevertheless, Shore shown a polynomial depth quantum circuit that solve the hidden abelian subgroup \cite{Shor_1997}, what is considered as breakthrough, as it made the computer science community to believe that a quantum computer might offer an exponential advantage.

Yet, even those that there is a general consensus about the superiority of ideal quantum computation model,it is still unclear that it feasible to implement such machine in the presence of noise.   
Still just point about the existences of noise is not powerful enough to cancel feasibility of computation and evidence of this is the fact that classical computers are also suffer form a certain rate of faults. Thus, for getting a full understandings of the hardness, let us compare two main reasons that made realize an hard task. 
First is the magnitude of the error rate, the classical computers also have errors, and sometimes when that happen we are wetness for systems failures (blue screen for example). The error rate of modern computers is so low such that the probability for error to propagate stay negligible even if the length of the computation is polynomial in the scale of what considered as reasonable input size. It's worth to mention, that in the area of exascale computing, when super computers preform around $10^{18}$ operations per second, It is hard to miss the faults. In quantum we become aware to their existences much more before.      

The second difference, which is a really tricky point, is that quantum sates are sensitive for additional type of error. Along with the chance for bit flip error, quantum state might change their phase. For example, consider the initial state $\ket{+} = \frac{1}{\sqrt{2}}\left( \ket{0} + \ket{1} \right)$, and suppose that due to noise the state transformed into $\frac{1}{\sqrt{4}}\left( \sqrt{3}\ket{0} + \ket{1} \right)$. While classical circuits are blind to such faults, namely their run would stay identical as no error occurs, Quantum circuits, usually, would affect and might fail. Furthermore, when planing a decoder for quantum error correction codes, If one is willing to use a classical code to defend against phase flips he has to make sure that the decoding itself doesn't translate bit flip errors. 
\begin{definition}[Bit and pahse flip.] \label{def:bphf}  
  Consider a quantum state $\ket{\psi}$ encoded in the computation base. We will say that a \textit{bit-flip} occurs in a scenario the operator Pauli $X$ applied on one of our state's qubits. The bit-flip event could be thought and be treated as exactly as the standard bit-flip error in the classical regime. In similar manner, \textit{phase-flip} occurs when the Pauli $Z$ applied on one of the qubits. 

  Notice that together with the identity $I$ the set $\{I, X \otimes e_{i} , Z \otimes e_{j} \}_{i,j \in [n]}$ span the matrices act on $n$ qubits.  
\end{definition}

However, even though quantum noise is so violent, It was proven that any ideal circuit at polynomial depth can be transformed to a robust circuit at poly-logarithmic cost \cite{aharonov1999faulttolerant}. Or in other words, There is a threshold, If the physicists would provide qubits and a finite gate set that suffer from a rate of noise below that threshold, than $BQP$, the class of polynomial time ideal quantum computation is feasible and could computed on realistic machine.                

The basic ingredient in \cite{aharonov1999faulttolerant} was to show the existence of quantum error correction code, such that one can perform all the logic operations in a way that restrict present errors from propagate on. That allow them separate any operation of the computation into stages, one of them is the operation itself, another one is an error correction stage. That process become with an additional cost, in both space and time, yet it might decrease the probability that the final state at the end would be faulted. The trade-off between the resource needed to pay and the decreasing rate define the threshold. And if the balance is positive then one can repeat in recursion manner, and after a log-log iterations the failure probability decay to zero while the circuit would scale at most poly-logarithmic wide and depth factors.      

Let's return back to repeation code presented in chapter 2. We would like to think about an analog, a first and natural attempt might considering to duplicate copies of the state, Unfortunately copying a general state is not a linear operation and therefore can not be done in the circuit model (and any other believed to be feasible).           


\begin{equation*}
  \begin{split}
    |\overline{0}\rangle&=\frac{1}{2\sqrt{2}}\left(|000\rangle+|111\rangle\right)^{\otimes3}\\
    |\overline{1}\rangle&=\frac{1}{2\sqrt{2}}\left(|000\rangle-|111\rangle\right)^{\otimes3}~.
  \end{split}
\end{equation*}

%\printbibliography[heading=subbibliography]
