\chapter{Quantum Error Correction Codes.}
\section{Introduction.}
It's widely believed that quantum machines have a significant advantage over the classical in the range of computational tasks\cite{grover1996fast}, \cite{ahuja1999quantum}. Simple algorithms could be interpreted as the quantum version of scanning all the options, cutting the running time by the square root of the classical magnitude. 

Nevertheless, Shore has shown a polynomial depth quantum circuit that solves the hidden abelian subgroup \cite{Shor_1997}, which is considered a breakthrough, as it made the computer science community believe that a quantum computer might offer an exponential advantage.

Yet, even though there is a consensus about the superiority of ideal quantum computation model, it is still unclear whether implementing such a machine in the presence of noise is feasible.   
Still, just pointing on the existence of noise is not powerful enough to cancel the feasibility of computation. Evidence of this is that classical computers also suffer from a certain rate of faults. Thus, to fully understand the hardness, let us compare two main reasons that made it realize a hard task. 
First is the magnitude of the error rate, classical computers also have errors, and sometimes we witness system failures (blue screen, for example). The error rate of modern computers is so low that the probability for error to propagate stays negligible even if the length of the computation is polynomial in the scale of what is considered reasonable input size. It's worth mentioning that in exascale computing when supercomputers perform around $10^{18}$ operations per second, It is hard to miss the faults. In quantum, we become aware of their existence much earlier.      

The second difference, which is a tricky point, is that quantum states are sensitive to additional types of error. Along with the chance for bit-flip error, a quantum state might also change its phase. For example, consider the initial state $\ket{+} = \frac{1}{\sqrt{2}}\left( \ket{0} + \ket{1} \right)$, and suppose that due to noise the state transformed into $\frac{1}{\sqrt{4}}\left( \sqrt{3}\ket{0} + \ket{1} \right)$. While classical circuits are blind to such faults. Namely, their run would stay identical as no error occurs. Quantum circuits usually would affect and might fail. Furthermore, when planning a decoder for quantum error correction codes, If one is willing to use a classical code to defend against phase flips, he has to ensure that the decoding doesn't cause bit-flip errors. 
\begin{definition}[Bit and pahse flip.] \label{def:bphf}  
  Consider a quantum state $\ket{\psi}$ encoded in the computation base. We will say that a \textit{bit-flip} occurs in a scenario the operator Pauli $X$ is applied on one of our state's qubits. The bit-flip event could be considered as exactly as the standard bit-flip error in the classical regime. Similarly, \textit{phase-flip} occurs when the Pauli $Z$ is applied on one of the qubits. 

  Notice that together with the identity $I$, the set $\{I, X \otimes e_{i} , Z \otimes e_{j} \}_{i,j \in [n]}$ span the matrices act on $n$ qubits.  
\end{definition}

However, even though quantum noise is so violent, It was proven that any ideal circuit at polynomial depth could be transformed to a robust circuit at poly-logarithmic cost \cite{aharonov1999faulttolerant}. Or in other words, There is a threshold, If the physicists would provide qubits and a finite gate set that suffers from a rate of noise below that threshold, then $BQP$, the class of polynomial time ideal quantum computation is feasible and could be computed on a realistic machine.                

The basic ingredient in \cite{aharonov1999faulttolerant} was to show the existence of quantum error correction code, such that one can perform all the logic operations in a way that restricts present errors from propagating on. That allows them to separate any operation of the computation into stages; one of them is the operation itself, another one is an error correction stage. That process comes with an additional cost, in both space and time, yet it might decrease the probability that the final state at the end would be faulted. The trade-off between the resource needed to pay and the decreasing rate defines the threshold. And if the balance is positive, then one can repeat in a recursion manner, and after log-log iterations, the failure probability decay to zero. At the same time, the circuit would scale at most poly-logarithmic wide and depth factors.      

Let's return to the repetition code presented in Chapter 2. We would like to have an analog; a first and natural attempt might consider duplicating copies of the state. Unfortunately, copying a general state is not a linear operation and therefore can not be done in the circuit model (and any other believed to be feasible). In particular there is no circuit $U$ which duplicate simultaneity the states $\ket{0}, \ket{1}, \ket{+}, \ket{-}$.

To overcome the issue, Shor came up with the nine-quibt code \cite{Ninequ}, which at first glance might seem a naive straightforward implantation of ``duplication'', but instead uses a clever insight about quantumness in general. Any operation can be seen as a linear (and even unitary) operation over a subspace embedded in large enough dimensions. The encoding is given as follow: 
\begin{equation*}
  \begin{split}
    |\overline{0}\rangle&=\frac{1}{2\sqrt{2}}\left(|000\rangle+|111\rangle\right)^{\otimes3}\\
    |\overline{1}\rangle&=\frac{1}{2\sqrt{2}}\left(|000\rangle-|111\rangle\right)^{\otimes3}~.
  \end{split}
\end{equation*}


For convenient let us use the notation, $\ket{\mathbf{GHZ}^{\pm}} =  \ket{0^{m}} \pm  \ket{1^{m}}$. One can also consider the Shor code over $m^{2}$ qubits which defined as above beside that any logical state contain $m$ product over $m$ qubits, So the state $\ket{\overline{0}}$ over $m^{2}$ qubits can be written as $\ket{\mathbf{GHZ}^{+}}^{m}$. We are now ready to prove a statement regards to the robustness.  

\begin{lemma}
  The Shor code over $9$ qubits enable to correct a single either bit or phase flip.  
\end{lemma}
So, it's clear that a single bit-flip fault can be treat exactly as in the classical case. The decoder will check that any of the triples store the same value, and if it's not the case then it will correct by majority. We will need the following claim to construct a decoder which also can correct a phase-flip fault.
\begin{claim}
  Let $H^{m}$ be applying of the Hadamard gate over each of the $m$ qubits. Then, $H^{m}\ket{\mathbf{GHZ}^{\pm}} = \sum_{ x \cdot \mathbf{1} =_2 \pm }{\ket{x} }$
\end{claim}

\begin{proof}

  \begin{equation*}
    \begin{split}
      H^{m}\ket{\mathbf{GHZ}^{\pm}} & = H^{m}\ket{0^{m}} \pm  H^{m}\ket{1^{m}} = \sum_{x \in \mathbb{F}_{2}^{m}}{\ket{x}} \pm  \sum_{x \in \mathbb{F}_{2}^{m}}{\left( -1 \right)^{x \cdot \mathbf{1}} \ket{x}} \\ & = \sum_{x \in \mathbb{F}_{2}^{m}}{ \left( 1 \pm \left( -1 \right)^{x \cdot \mathbf{1}}  \right) \ket{x} } =  \sum_{x \cdot \mathbf{1} =_2 \pm }{\ket{x} }
    \end{split}
  \end{equation*}
\end{proof}



By quadric the dimension of the repetition code one can find those state which at least two pauli are needed to applay for flipping either the bit or the phase of the logic state. Clearly any phase flip      


\input{../NLTES_project/ltc_ldpc/qpolycode.tex}


%\printbibliography[heading=subbibliography]

