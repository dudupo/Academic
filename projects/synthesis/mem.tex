

%\newcommand*{\ACM}{}%

\ifdefined\ACM

%\documentclass[sigplan,screen]{acmart}
\documentclass[manuscript,screen,review]{acmart}

\else
 \documentclass[14pt]{article}
%\usepackage{libertine}
\usepackage{cuted}%\usepackage{widetext}
\input{./usepackage}
\usepackage{cancel}
\usepackage{subcaption}
\addbibresource{./sample.bib}

\fi

\begin{document}
\input{newcommands}
%\title{ $\textbf{QNC}_{1} \subset $ noisy-\textbf{BQP}}
\title{ Memory. }
%\author{Michael Ben-Or \ \ David Ponarovsky}
\maketitle

\newcommand*{\Mbas}{\mathcal{X}^\prime}
\newcommand*{\bas}{\mathcal{X}}
\newcommand*{\sMbas}{\Mbas}
\newcommand*{\QQ}{C_{X}/C_{Z}^\perp }
\newcommand*{\trig}{ Triorthogonal }
\newcommand*{\Hyp}{ Hyperproduct }
\newcommand*{\Cin}{ C_{\text{initial}} }
\newcommand*{\Ctan}{ C_{\text{Tan}} }



\newcommand*{\QACze}{\mathbf{QAC}_{0}}
\newcommand*{\QNCzef}{\mathbf{QNC}_{0,f}}
\newcommand*{\QNCze}{\mathbf{QNC}_{0}}
\newcommand*{\QNCon}{\mathbf{QNC}_{1}}
\newcommand*{\NCon}{\mathbf{NC}_{1}}
\newcommand*{\noiseQNCon}{noisy-$\QNCon$}
\newcommand*{\QNC}{\mathbf{QNC}}
\newcommand*{\QNCG}{\mathbf{QNC_G}}
\newcommand*{\NC}{\mathbf{NC}}
\newcommand*{\QNCiG}{\mathbf{QNC_{G,i}}}


% Constant depth fault tolerance construction.   
\newcommand*{\CDO} {CDFT} 

\section{Relaxation to The Fault Tolerance Model.} We are interested in the following extension to the fault tolerance circuit model. We are equipped with additional type, in each turn a strong entity, on which we trust, set an hint $I_{t}$ on the type. We would like to minimize $|I| := \min_{t} |I_{t}|$. In particular, A fault tolerance construction in the standard model exhibits a fault tolerance construction in the relaxed model with $|I| = 0$.      

Another example, is using the hints given by the strong entity for either  deciding what correction should be applied or what 'gate-teleportation correction' should be applied. It easy to check that previews constructions  gives relaxed fault tolerance such:     
\begin{enumerate}
  \item They output an encoded states with non-trivial distance. 
  \item The exhibit only a constant overhead in depth. 
  \item At each turn $|I_{t}| / \text{ logical qubits } $ depends on the code length.  
\end{enumerate}
That brings us to ask the following:
\begin{oproblem}
  Is there a relaxed fault tolerance scheme that enjoys form the first and the second bullets above, yet requires hint at length which is constant per logical qubit? Namely:   
  \begin{equation*}
    \begin{split}
      \frac{ |I| } { \text{ logical qubits } } = O(1) ? 
    \end{split}
  \end{equation*}
\end{oproblem}

\newcommand{\TT}{ \mathcal{T} }

\section{Notations and Definitions.} Consider a code with a left $k$-colorized Tanner graph $\TT{}$, such that any two left bits of the same color share no check. For a subset of bits $S$, we denote by $S_{c_1}$ its restriction to color $c_1$. We use the integer $\Delta$ to denote the right degree of $\TT{}$. Our computation is subjected to $p$-depolarized noise. We denote by $m$ the block length of the code. The decoder works as follows:
\begin{enumerate}
  \item On the hint-type Pick a random color. 

    \ctt{In the relaxed version: the 'right/best' color is given by the strong entity.} 
  \item For any (q)bit at that color, check if flipping it decreases the syndrome. If so, then flip it.
\end{enumerate}


%We say that a density matrix $\rho$, induced on the $m$-length block, is a \textbf{good noisy distribution} if:
%\begin{enumerate}
  %\item $\rho$ is subjected to $q$ - local stochastic noise. 
  %\item Denote by $S$ the support of an error occurring on $\rho$ (S is a random variable). Then, with high probability\footnote{I'm leaving specifying what it is to later.}, $|S_{c_{1}}| > \frac{1}{4} |S|$. 
%\end{enumerate}


\begin{claim}
  Let $\TT$ be a tanner graph such $\Delta > 2k$. There is $p_{0} \in (0,1)$ and $q \in (0,1)$ such for any $p < p_{0}$ and a density $\rho$, which is subjected to $q$-local stochastic noise, then, there is a color $c_{1}$ such after a cycle of absorbing $p$-depolarized noise and correcting according to the decoding rule when color$=c_{1}$, the result state $\rho^\prime$ will remain a subjected to $q$-local stochastic noise.  
\end{claim}
\begin{figure}[h]
  \begin{center}
  \tikz{ 
    \node  (A) at (1,0) { Given - $\rho$ };
    \node  (B) at (5,0) { Decoding };
    \node  (C) at (9,0) { $p$-depololraized };
    \draw[->] (A) to (B); 
    \draw[->] (B) to (C); 

    \node  (E) at (1,-1) { $E_{1}$ };
    \node  (D) at (5,-1) { $E_{2}$ };
    \node  (F) at (9,-1) { $E_{3}$ };

    \draw[->] (A) to (E); 
    \draw[->] (B) to (D); 
    \draw[->] (C) to (F); 
  }
\end{center}
\caption{Illustration of the cycle.}
\end{figure}
\subsection{Proof.}
First, let's bound the probability that the error after the decoding round ($E_{2}$) is supported on $S$. (We use here the fact that views of the bits through their stabilizer don't overlap since we took only bits of the same color for the decoding):
\begin{equation*}
  \begin{split}
    \prb{ \Su{} \left(E_{2}\right) = S } \le \prb{\text{any bit } v\in S_{c_{1}} \text{ sees majority of satisfied checks   } } \le q^{\frac{1}{2}\Delta |S|_{c_{1}}}
  \end{split}
\end{equation*}
Now, for roughly analyzing the error after observing a round of $p$-depolarized noise, we consider a model in which new errors due to the depolarized channel don't correct previous errors. So we get:
\begin{equation*}
  \begin{split}
    \prb{ \Su{} \left(E_{3}\right) = S   } & \le  \sum_{S^{\prime} \subset S }{q^{\frac{1}{2}\Delta|S^{\prime}|_{c_{1}}}p^{|S /S^{\prime}|}  }  %+  \prb{  | \Su{} \left( E_{2} \right)_{c_1} | < \frac{1}{4} | \Su{} \left( E_{2} \right) |} \\
    %&\le \left( q^{\frac{1}{4}\Delta} + p \right)^{|S|}  + \prb{  | \Su{} \left( E_{2} \right)_{c_1} | < \frac{1}{4} | \Su{} \left( E_{2} \right) |} 
  \end{split}
\end{equation*}

On the other hand, 
\begin{equation*}
  \begin{split}
    \sum_{c_{i}}|S|_{c_{i}} &= k\cdot \expp{|S|_{c_{i}}} = |S| \\
    & \Rightarrow \max_{c_i}|S|_{c_{i}} \ge \frac{1}{k}|S|
  \end{split}
\end{equation*}
So if $c_{1}$ is the color which maximize $|S|_{c_1}$ then:  

\begin{equation*}
  \begin{split}
    \prb{ \Su{} \left(E_{3}\right) = S   } &  \le \sum_{S^{\prime} \subset S }{q^{\frac{1}{2}\Delta|S^{\prime}| / k }p^{|S /S^{\prime}|}  } \\
    &\le \left( q^{\frac{1}{2k}\Delta} + p \right)^{|S|} \le q^{|S|} 
  \end{split}
\end{equation*}
\newcommand*{\Pt}{\mathcal{P}}


\section{Suitable Codes.}  
We first show that the partition code has presentation (a check matrix) for which the induced $\TT$ satisfies the relation $\Delta > 4k$, and then show that the hypergraph product code defined by multiple the tanner graphs of that representation gives $\Delta > 2k$.

\begin{claim}
  Let $C$ be a code with a tanner graph $\TT$, denote by $\TT^\top$ the tanner graph of the transpose code and by $Q\left(\TT \times \TT^\top\right) $ the tanner graph obtained by the hypergraph product. Then:  
  \begin{enumerate}
    \item $ \Delta\left(Q\left(\TT \times \TT^\top\right)\right) = \max \{  \Delta(\TT), \Delta(\TT^{\top}) \} $ 
    \item $ k\left(Q\left(\TT \times \TT^\top\right)\right) \le  k(\TT) + k(\TT^{\top})$ 
  \end{enumerate}
\end{claim}

\begin{proof} Easy.
\end{proof}

\begin{claim}
  The repetition code has a representation, for which $\Delta > 4k$. 
\end{claim}
\begin{proof}
  Denote by $H_{0}$ the checks obtained by treating the repetition code as Tanner code over the cyclic graph. Observes, that $k_{0} = 2$ and $\Delta_{0} = 2$.  

  Now, let $V^{+}, V^{-}$ a partition of the bits according their color. Any check that of the form $v^{+} + v^{-}$ where $v^{\pm} \in V^{\pm}$ agrees with the coloring. So, by adding perfect matching we increase $\Delta$ by $1$ and keep the colorization. We have $n/2!$ such matchings, so we can add $100\Delta$ and gets the correction of the proof.   

  Furthermore, the length of the transposed code increases by the number of the checks we add, and it's distance can't decrease. So, we get that the parameters of the transposed code are $[n + 100\Delta n, 1, \ge n ]$.    
\end{proof}


So, it remains to show that property (2) still holds with high probability. The following is incorrect, yet almost correct. I want to say that a new error observed by the depolarized channel has to spread evenly on bits at color $c_{1}$, and by concentration get that they are far away from $\frac{1}{4}$ with probability less than $\text{exp}( - \varepsilon m )$.

Then, let $S^{t} = \Su \left(E\right) $ at time $t$ and denote by $\Pt_{t}$ the probability that $|S^{t}_{c_{1}}| > \frac{1}{4}|S^{t}|$. Then:
\begin{equation*}
  \begin{split}
    \Pt_{t+1} &\ge \prb{ |S^{t}_{c_{1}}| > \frac{1}{4}|S_{t}| \text{ and }  | \left( S_{t+1}/S_{t} \right)_{c_1}  | \ge \frac{1}{4}|S_{t+1}/S_{t}|  }  \\
    &\ge \Pt_{t} \cdot \left( 1 - e^{- \varepsilon m}   \right) \ge \Pt_{0}\left( 1 - e^{- \varepsilon m } \right)^{t+1} \\ 
    & \ge \Pt_{0}\left( 1 - (t+1) e^{- \varepsilon m } \right)
  \end{split}
\end{equation*}

There is a problem with the assumption that the new error spreads uniformly across the colors. In particular, $m$ should be taken as the untapped qubits, so it changes over time and might not contain qubits of color $c_{1}$ at all.


  %\section{ Strategies to get \CDO. }  \label{sec:opt}
 %
%The second gadget is Memory, a particular type of code which allows restraining the error rate by exhibiting a constant depth procedure that, when promising that the error rate is below a threshold, suppresses the error by at least a constant factor. Using memory, we will be able to promise with high probability that the error rate is lower than some fraction. 
%
 %\subsection{Memory.} 
 %\newcommand*{\DD}{\mathbf{D} }
%Informal memory code is a code that stores a logical state for a long time while keeping the noise below a certain amount. We define it formally by saying that memory codes will reduce an error that affects at most $\beta$ portion of the qubits into an error that affects at most $\gamma$ portion of the qubits.
%
 %\begin{definition}[Ideal $(\beta,\gamma)$-Memory]
   %We say that a (quantum) error correction code $C$ is an Ideal $(\beta,\gamma)$-Memory code if there is a constant depth procedure $\DD$ such that for any $I$ of size $|I| \ge (1 - \beta) n$ and a mixed states $\sigma$ and $\rho$ such $\sigma$ distributed over the $C$'s codewords $\sigma \in C$ and $\Tr_{I}\left(\rho\right) = \Tr_{I}\left(\sigma\right)$, we have that there is subset of qubits $J$ at size at least $(1-\gamma)n$:
   %\begin{equation*}
     %\begin{split}
        %\Tr_{J} \DD \left(\rho\right) = \Tr_{J}\left(\sigma\right) 
     %\end{split}
   %\end{equation*}
%
 %\end{definition}
%We would like to extend the memory gadgets to work with high probability, which motivates us to define the following:
%\newcommand*{\Po}{\mathcal{P}_{1}}
%\newcommand*{\Pt}{\mathcal{P}_{2}}
%\newcommand*{\Nn}{\mathcal{N}}
%\begin{definition}[ $\left(\Po,\Pt \right)$- thermal couple. ]
%Let $\Po,\Pt$ be sets of density matrices induced over the $n$-qubit Hilbert space, and let $\Nn$ be a $p$-stochastic local noise channel for some constant $p \in (0,1)$. We say that the couple $\left(\Po,\Pt \right)$ is a thermal couple if for any $\rho \in \Pt$, we have $\Nn(\rho) \in \Po$ with high probability.
%\end{definition}
%
 %\begin{definition}[$(\Po,\Pt)$-Memory]
   %Consider a $\left(\Po,\Pt \right)$- thermal couple, We say that C is a $(\Po, \Pt)$-Memory if there is a constant depth procedure $\DD$, such that for any $\rho \in \Po$ we have $\DD\left( \rho \right) \in \Pt$, with high probability. 
 %\end{definition}
 %For example, consider a code $C$ with a $\Delta$-regular Tanner graph. Let $\Po$ be all the noisy states derived from codewords in $C$ such that the syndrome graph induced by them can be decomposed into disjoint $\Delta/2$-connected components $A_{1},A_{2},..A_{l}$, each of size at most $|A_{i}| < \beta \sqrt{n}$, and the $\Delta/2$-distance between any two of them $A_{i}, A_{j}$, namely the number of edges needed to add to merge them into one single $\Delta/2$-connected component, is at least $\theta \min \left( |A_{i}|, |A_{j}| \right)$. We call such decomposition characterization $(\beta \sqrt{n}, \theta )$ error decomposition. 
%
 %Now let $\Pt$ be all the deviations from $C$, such that the syndrome graph induced by them can be decomposed into $(\gamma \sqrt{n}, \frac{\beta}{\gamma}  \theta )$ error decomposition. The couple $\left( \Po, \Pt \right)$ is thermal couple, And combining the quantum expander code and the parallel small set-flip decoder \cite{grospellier:tel-03364419} they defines a $\left( \Po, \Pt \right)$-memory. 
%
%
 %\newcommand{\Px}[2]{P^{(v)}_{#1}(#2)}
%
%\begin{claim}
  %The probability to have $\Px{\alpha\Delta}{x} \le $ 
%\end{claim}
%
%\begin{claim}
  %Any $\alpha\Delta$-connected component $E$ can be decompized to $\alpha\Delta-1$ connected component and more $\Theta( E/\Delta^{3})$ edges. 
%\end{claim}
%
%\begin{proof}
  %$E$ is connected. Let $T$ be its spanning tree. Now consider $Y$, a subset of edges obtained by colorizing from any vertex at an odd level of $T$ a single forward edge. And let $E^{\prime} = E/Y$. First, observes that $E$ is an $\alpha\Delta - 1$ connecnted componnent. On the otherhand: 
  %\begin{equation*}
    %\begin{split}
      %|Y| &= \frac{1}{\Delta-1}\sum_{i}^{h/2} E\left( T^{2i + 1} \right) =  \frac{1}{\Delta-1}\sum_{i}^{h/2} \frac{1}{2} \left( E\left( T^{2i + 1} \right)+ E\left( T^{2i + 1} \right) \right) \\  
      %& \ge \frac{1}{\Delta-1}\sum_{i}^{h/2} \frac{1}{2} \frac{1}{\Delta} \left( E\left( T^{2i + 1} \right)+ E\left( T^{2i} \right) \right) = \frac{1}{2 \left( \Delta - 1 \right) \Delta }|T| \\ 
      %& \ge \frac{1}{2 \left( \Delta - 1 \right) \Delta } \frac{1}{\Delta}|E| \ge \frac{1}{2\Delta^{3}}|E|  \\
      %& \left( \ge \frac{1}{2 (\Delta - 1) \Delta } \left( V(T) - 1 \right)     \right) 
    %\end{split}
  %\end{equation*}
%\end{proof}
%
%
%\begin{proof}
  %Assume that $J$ is vertices subset that support an $\alpha\Delta$ connected $E$ in $G$, then it's also the support of $\alpha\Delta -1$ connected, denote by $E^{\prime}$ that sub componnent. So we can construct $E$ by first sample $E^{\prime}$ and then find a mathcing between the left veritcis. Thus:  
  %\begin{equation*}
    %\begin{split}
      %\Px{\alpha\Delta}{x} \le \Px{\alpha\Delta - 1}{x} \cdot (p)^{\frac{x}{2\Delta^{2}}} \le ( p)^{\frac{x}{2 \Delta^{2} } \alpha \Delta } =  ( p)^{\frac{\alpha \Delta }{2 } x}
    %\end{split}
  %\end{equation*}
%\end{proof}
%
%\begin{claim}
  %The ptobability to have $n^{\varepsilon}$ connencted component is: 
%\end{claim}
%\begin{proof}
  %\begin{equation*}
    %\begin{split}
      %\le &  n \sum_{n^{\varepsilon}}^{n} \sum_{v \in V}\Px{\alpha\Delta}{x}   
      %\le     n  \frac{  (\Delta p)^{\frac{n^{\varepsilon}}{2} \alpha \Delta }}{ 1  - (\Delta p)^{ \frac{1}{2}\alpha \Delta }} \rightarrow 0 
    %\end{split}
  %\end{equation*}
%\end{proof}
%
%
%
%
%
%
%
%
  %\newcommand{\sliceb}[1]{ \slice[style=blue, label style={inner sep=1pt,anchor=south west,rotate=40}]{#1}}
%
%%\slice{ $\gamma\left( c \alpha + p  \right) + p < \alpha $ error rate. }
%%\slice{ $c\alpha + p$ error rate.  } 
  %%row sep=0.3cm, column sep=0.7cm,
%%slice style=blue,slice label style={inner sep=1pt,anchor=south west,rotate=40}
  %% \slice{ $\rho$ at $\alpha$ error rate. }
  %\begin{figure}[h]
    %\centering
    %\begin{quantikz}[slice style=blue,slice label style={inner sep=1pt,anchor=south west,rotate=40}]
      %\lstick{$q_1$} & \qw & \qw & \qw &  \sliceb{  $ \rho$ at $\alpha$ error rate.  }  & \gate[wires=9][1.7cm]{U}  \sliceb{ $c\alpha + p$ error rate.  }  & \gate[wires=9][1.7cm]{ F }  & \gate{\mathcal{N}}  \sliceb{ $\gamma\left( c \alpha + p  \right) + p < \alpha $ error rate. }& \qw & \\
  %\lstick{$q_2$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & \\
  %\lstick{$q_3$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & \\
  %\lstick{$q_4$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & \\
  %\lstick{$q_5$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & \\
  %\lstick{$q_6$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & \\
  %\lstick{$q_7$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & \\
  %\lstick{$q_8$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & \\
  %\lstick{$q_9$} & \qw & \qw & \qw &  &                  &    & \gate{\mathcal{N}} & \qw & 
%\end{quantikz}
%\caption{ Usage of  Ideal $(\beta,\gamma)$-Memory to obtain fault tolerance computation. }
    %\label{fig:mem}
  %\end{figure}

( \ctt{ See the comment in blue below, it gets complicated.} )



\textbf{Question.}  
Consider the $n$-dimensional toric code, where qubits are placed on $k$-cells of the $n$-dimensional hypercubic lattice.  
For an $i$-cell, denote by $\Delta_i^{+}$ the number of $(i{+}1)$-cells adjacent to it, and by $\Delta_i^{-}$ the number of $(i{-}1)$-cells adjacent to it.  
For which values of $k$ do both of the following strict inequalities hold?
\[
\Delta_k^{+} > \Delta_{k+1}^{-}, \qquad \Delta_k^{-} > \Delta_{k-1}^{+}.
\]

\textbf{Answer.}  
In an $n$-dimensional hypercubic lattice one has
\[
\Delta_i^{+} = 2\,(n-i), \qquad \Delta_i^{-} = 2\,i.
\]
Therefore, the two inequalities become
\[
2(n-k) > 2(k+1) \quad\iff\quad k < \tfrac{n-1}{2},
\]
\[
2k > 2\bigl(n-(k-1)\bigr) \quad\iff\quad k > \tfrac{n+1}{2}.
\]
These conditions are mutually exclusive, since they require simultaneously
\[
k < \frac{n-1}{2} \quad \text{and} \quad k > \frac{n+1}{2}.
\]
Thus, there is no value of $k$ (for any dimension $n$) for which both inequalities hold at once.  

%In particular, for the $10$-dimensional toric code, condition (A) requires $k<4.5$ while condition (B) requires $k>5.5$, which is impossible. Hence, no such $k$ exists

Yet, if one is willing to satisfy only the first inequality. Then: 
\begin{equation*}
  \begin{split}
    1 < \frac{\Delta_{k}^{-}}{\Delta_{k-1}^{+}} = \frac{2k}{2(n-(k-1))} \rightarrow k > \frac{2}{3}n
  \end{split}
\end{equation*}

\textbf{Should be verified:}
\begin{enumerate}
  \item In addition the dimension of the code should be ${ n \choose k } $. (Also known as the Betti numbers). 
  \item Numebr of $k$-cells shared by a $j$ - cell and a $i$ -cell. $  { j - i \choose  k- i }  $. 
  \item The partiy of ${ 2l \choose l }  $.  
  \item should understand: \href{https://math.stackexchange.com/questions/3242404/homology-of-n-dimensional-torus}{Math stachexhange}.
\end{enumerate}


\end{document}


